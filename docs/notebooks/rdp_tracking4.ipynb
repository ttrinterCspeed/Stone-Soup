{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDP - Stone Soup Experiments\n",
    "[Documentation](https://stonesoup.readthedocs.io/en/v1.4/auto_examples/readers/Custom_Pandas_Dataloader.html#sphx-glr-auto-examples-readers-custom-pandas-dataloader-py)\n",
    "\n",
    "Continuing experiments - following tutorial #4: Particle Filter\n",
    "\n",
    "### Got Nowhere\n",
    "Not quite understanding how this works, or doesn't work. The predictions don't follow the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "from importlib import reload  # Python 3.4+\n",
    "from typing import Tuple\n",
    "import itertools\n",
    "from matplotlib import pyplot as plt\n",
    "from math import ceil\n",
    "\n",
    "import dateutil\n",
    "from pymap3d import geodetic2enu\n",
    "\n",
    "import sys\n",
    "sys.path.append('C:/Users/ttrinter/git_repo/cspeed/data_common')\n",
    "sys.path.append('../../..')\n",
    "import data_functions as dfunc\n",
    "import visualizations as v\n",
    "from ttt_ss_funcs import generate_timestamps, ADSBTruthReader, CSVReaderXY, CSVReaderPolar, plot_all\n",
    "\n",
    "from stonesoup.reader import DetectionReader, GroundTruthReader\n",
    "from stonesoup.base import Property\n",
    "from stonesoup.types.detection import Detection\n",
    "from stonesoup.plotter import AnimatedPlotterly\n",
    "\n",
    "from stonesoup.base import Property\n",
    "from stonesoup.buffered_generator import BufferedGenerator\n",
    "from stonesoup.functions import cart2sphere, sphere2cart\n",
    "from stonesoup.models.measurement.linear import LinearGaussian\n",
    "from stonesoup.models.measurement.nonlinear import CartesianToBearingRange\n",
    "from stonesoup.types.angle import Bearing\n",
    "from stonesoup.types.detection import Detection\n",
    "from stonesoup.types.groundtruth import GroundTruthState, GroundTruthPath\n",
    "\n",
    "# Tracker Imports\n",
    "from stonesoup.types.state import GaussianState\n",
    "\n",
    "sensor_positions = { 'RDU103': (51.52126391, 5.85862734)}\n",
    "\n",
    "METERS_in_NM = 1852\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data from BigQuery\n",
    "* rdp_straight: short, straight flight path\n",
    "* rdp_extended: longer flight path\n",
    "* adsb_straight: truth for rdp_straight\n",
    "* adsb_extended: truth for rdp_extended\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save/Read  to/from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi\n",
    "data_dir = 'C:/Users/ttrinter/git_repo/Stone-Soup/data'\n",
    "adsb_file = f'{data_dir}/adsb_straight.csv'\n",
    "adsb_data = pd.read_csv(adsb_file)\n",
    "adsb_data['timestamp'] = pd.to_datetime(adsb_data['timestamp'], errors='coerce')\n",
    "adsb_data = adsb_data.loc[~adsb_data['timestamp'].isna()]\n",
    "adsb_data['timestamp'] = pd.to_datetime(adsb_data['timestamp'], errors='coerce')\n",
    "adsb_data['timestamp'] = adsb_data['timestamp'].dt.tz_localize(None)\n",
    "\n",
    "rdp_file = f'{data_dir}/rdp_straight.csv'\n",
    "rdp_data = pd.read_csv(rdp_file)\n",
    "rdp_data['timestamp'] = pd.to_datetime(rdp_data['timestamp'], errors='coerce')\n",
    "rdp_data['timestamp'] = rdp_data['timestamp'].dt.tz_localize(None)\n",
    "\n",
    "# Matched Plots\n",
    "matched_csv = f'{data_dir}/rdp_matched.csv'\n",
    "rdp_matched = pd.read_csv(matched_csv)\n",
    "rdp_matched['timestamp'] = pd.to_datetime(rdp_matched['timestamp'], errors='coerce')\n",
    "rdp_matched['timestamp'] = rdp_matched['timestamp'].dt.tz_localize(None)\n",
    "\n",
    "start_time = rdp_matched['timestamp'].min()\n",
    "end_time = rdp_matched['timestamp'].max()\n",
    "\n",
    "print(f'ADSB: {len(adsb_data)}')\n",
    "print(f'RDP: {len(rdp_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matched Data Set\n",
    "To make things even simpler, I'll grab the set of matched data for this test plane. Then most of the plots should be \"true\" detections. Let's see how the tracker does with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_address = 10537421\n",
    "\n",
    "file_dir = 'C:/Users/ttrinter/OneDrive - cspeed.com (1)/Documents/Data/Travis/2024-07-17'\n",
    "matched_file = '20240717_Travis_matched_rdp_61.xlsx'\n",
    "matched_data = pd.read_excel(f'{file_dir}/{matched_file}')\n",
    "matched_data = matched_data.loc[(matched_data.target_address==target_address) &\n",
    "                                (matched_data.close_enough==True)]\n",
    "matched_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_plot = v.plot_target_match2(matching=matched_data, \n",
    "                                    target_address=target_address, \n",
    "                                    plot_show=True, \n",
    "                                    pd_loc='title')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detections\n",
    "matched_xy = CSVReaderXY(matched_csv)\n",
    "matched_polar = CSVReaderPolar(matched_csv)\n",
    "\n",
    "# ADSB\n",
    "adsb = ADSBTruthReader.multiple_ground_truth_reader([adsb_file])\n",
    "\n",
    "dets = [next(iter(detection[1])) for detection in matched_xy.detections_gen()]\n",
    "\n",
    "timestamps = generate_timestamps(start_time, end_time)\n",
    "plot_all(dets, adsb, start_time, end_time, plot_type='animated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Tutorial #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stonesoup.models.transition.linear import CombinedLinearGaussianTransitionModel, \\\n",
    "                                               ConstantVelocity\n",
    "\n",
    "from stonesoup.predictor.particle import ParticlePredictor\n",
    "from stonesoup.resampler.particle import ESSResampler\n",
    "from stonesoup.updater.particle import ParticleUpdater\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "from stonesoup.types.numeric import Probability  # Similar to a float type\n",
    "from stonesoup.types.state import ParticleState\n",
    "from stonesoup.types.array import StateVectors\n",
    "from stonesoup.types.hypothesis import SingleHypothesis\n",
    "from stonesoup.types.track import Track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the particle filter\n",
    "Analogously to the Kalman family, we create a `ParticlePredictor` and a `ParticleUpdater` which take responsibility for the predict and update steps respectively. These require a `TransitionModel` and `MeasurementModel` as before.\n",
    "To cope with sample sparsity we also include a resampler, in this instance `SystematicResampler`, which is passed to the updater. It should be noted that there are many resampling schemes, and almost as many choices as to when to undertake resampling. The systematic resampler is described in [#]_, and in what follows below resampling is undertaken at each time-step. More resamplers that are included in Stone Soup are covered in the [Resampler Tutorial](https://stonesoup.readthedocs.io/en/latest/auto_tutorials/sampling/ResamplingTutorial.html#sphx-glr-auto-tutorials-sampling-resamplingtutorial-py)\n",
    "\n",
    "### Use of Effective Sample Size resampler (ESS)\n",
    "Resampling removes particles with a low weight and duplicates particles with a high weight. A side effect of this is that additional variance is added. Use of `SystematicResampler` at each time-step means that additional variance is being introduced when it may not necessarily be required. To reduce the additional variance, it may be optimal to resample less frequently.\n",
    "\n",
    "The Effective Sample Size resampler (`ESSResampler`) compares the variance of the unnormalised weights of the particles to a pre-specified threshold, and only resamples when the variance is greater than this threshold. This threshold is often calculated by the ESS criterion (at time n) given by:\n",
    "$$\n",
    "           ESS = \\left(\\sum_{i=1}^{N} (W_{n}^i)^2\\right)^{-1}\n",
    "$$\n",
    "\n",
    "### Initialise a prior\n",
    "To start we create a prior estimate. This is a `ParticleState` which describes the state as a distribution of particles using `StateVectors` and weights. This is sampled from the Gaussian distribution (using the same parameters we had in the previous examples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_particles = 1000\n",
    "\n",
    "# Sample from the prior Gaussian distribution\n",
    "samples = multivariate_normal.rvs(np.array([0, 50, 0, 50]),\n",
    "                                  np.diag([5, 0, 5, 0]),\n",
    "                                  size=number_particles)\n",
    "\n",
    "# Create prior particle state.\n",
    "prior = ParticleState(state_vector=StateVectors(samples.T),\n",
    "                      weight=np.array([Probability(1/number_particles)]*number_particles),\n",
    "                      timestamp=start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measurement Model\n",
    "measurement_model = LinearGaussian(\n",
    "    ndim_state=4,   # Number of state dimensions (position and velocity in 2D)\n",
    "    mapping=(0, 2), # Mapping measurement vector index to state index\n",
    "    noise_covar=np.array([[5, 0 ],  \n",
    "                          [0, 5]])\n",
    "    )  #Covariance matrix for Gaussian PDF\n",
    "\n",
    "# Transition Model\n",
    "q_x = 50\n",
    "q_y = 50\n",
    "transition_model = CombinedLinearGaussianTransitionModel([ConstantVelocity(q_x),\n",
    "                                                          ConstantVelocity(q_y)])\n",
    "\n",
    "predictor = ParticlePredictor(transition_model)\n",
    "resampler = ESSResampler()\n",
    "updater = ParticleUpdater(measurement_model, resampler)\n",
    "\n",
    "start_time = min(timestamps)\n",
    "\n",
    "track = Track()\n",
    "\n",
    "for det in dets:\n",
    "    prediction = predictor.predict(prior, timestamp=det.timestamp)\n",
    "    # print(det.timestamp)\n",
    "    hypothesis = SingleHypothesis(prediction, det)   # Group a prediction and measurement\n",
    "    post = updater.update(hypothesis)\n",
    "    track.append(post)\n",
    "    prior = track[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = AnimatedPlotterly(timestamps, tail_length=.5)\n",
    "\n",
    "plotter.plot_tracks(track, [0, 2], particle=True, plot_history=False)\n",
    "\n",
    "plotter.plot_measurements(dets,\n",
    "                          mapping=[0, 2],\n",
    "                          measurements_label='Test Data',\n",
    "                          marker=dict(color='rgba(255, 0, 0, 0.7)',\n",
    "                                      size=5, \n",
    "                                      symbol=\"cross\"))\n",
    "\n",
    "plotter.fig.update_layout(title={'text': \"Test Track - Cartesian - Unscented Kalman\", \n",
    "                                 'x': 0.5, \n",
    "                                 'xanchor': 'center', \n",
    "                                 'yanchor':  'top'})\n",
    "\n",
    "plotter.fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the starting prior didn't change the results much at all - so not very sensitive to that! However, the first track point is always oddly somewhere between the radar and the actual first observation. Maybe this will clean up in later iterations of the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polar Coordinates\n",
    "Trying again, but changing the process to read rho and theta and, maybe later also radial velocity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdp = RDPReader(rdp_file,\n",
    "start_time = rdp_matched['timestamp'].min()\n",
    "end_time = rdp_matched['timestamp'].max()\n",
    "timestamps = generate_timestamps(start_time, end_time)\n",
    "\n",
    "# Detections\n",
    "meas_polar = CSVReaderPolar(matched_csv)\n",
    "\n",
    "# Ground Truth\n",
    "adsb = ADSBTruthReader(adsb_file)\n",
    "ground_truth = set()\n",
    "for time, truths in adsb:\n",
    "    ground_truth.update(truths)\n",
    "\n",
    "dets = [next(iter(detection[1])) for detection in meas_polar.detections_gen()]\n",
    "\n",
    "plotter = AnimatedPlotterly(timestamps, tail_length=0.3, sim_duration=1)\n",
    "\n",
    "#Animated\n",
    "plotter.plot_ground_truths(ground_truth, \n",
    "                           mapping=[0, 2], \n",
    "                           mode='markers', \n",
    "                           marker=dict(color='rgba(0, 0, 255, 0.2)',\n",
    "                                      size=5, \n",
    "                                      symbol=\"square-open\")\n",
    "                            )\n",
    "\n",
    "plotter.plot_measurements(dets,\n",
    "                          mapping=[0, 2],\n",
    "                          measurements_label='Test Data',\n",
    "                          marker=dict(color='rgba(255, 0, 0, 0.7)',\n",
    "                                      size=5, \n",
    "                                      symbol=\"cross\"),\n",
    "                          convert_measurements=True\n",
    ")\n",
    "\n",
    "plotter.fig.update_layout(title={'text': \"Test Track - Polar\", \n",
    "                                 'x': 0.5, \n",
    "                                 'xanchor': 'center', \n",
    "                                 'yanchor':  'top'})\n",
    "# plt.grid()\n",
    "plotter.fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particle Filtering Again\n",
    "\n",
    "#### Reset the Prior Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_particles = 1000\n",
    "\n",
    "# Sample from the prior Gaussian distribution\n",
    "samples = multivariate_normal.rvs(np.array([0, 1, 0, 1]),\n",
    "                                  np.diag([1.5, 0.5, 1.5, 0.5]),\n",
    "                                  size=number_particles)\n",
    "\n",
    "# Create prior particle state.\n",
    "prior = ParticleState(state_vector=StateVectors(samples.T),\n",
    "                      weight=np.array([Probability(1/number_particles)]*number_particles),\n",
    "                      timestamp=start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = ParticlePredictor(transition_model)\n",
    "resampler = ESSResampler()\n",
    "updater = ParticleUpdater(measurement_model, resampler)\n",
    "\n",
    "start_time = min(timestamps)\n",
    "\n",
    "track = Track()\n",
    "\n",
    "dets = [next(iter(detection[1])) for detection in meas_polar.detections_gen()]\n",
    "for det in dets:\n",
    "    prediction = predictor.predict(prior, timestamp=det.timestamp)\n",
    "    # print(det.timestamp)\n",
    "    hypothesis = SingleHypothesis(prediction, det)   # Group a prediction and measurement\n",
    "    post = updater.update(hypothesis)\n",
    "    track.append(post)\n",
    "    prior = track[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = AnimatedPlotterly(timestamps, tail_length=0.3, sim_duration=1)\n",
    "\n",
    "plotter.plot_tracks(track, [0, 2], uncertainty=True, particle=True)\n",
    "\n",
    "plotter.plot_measurements(dets,\n",
    "                          mapping=[0, 2],\n",
    "                          measurements_label='Test Data',\n",
    "                          marker=dict(color='rgba(255, 0, 0, 0.7)',\n",
    "                                      size=5, \n",
    "                                      symbol=\"cross\"),\n",
    "                          convert_measurements=True)\n",
    "\n",
    "plotter.fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asterix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

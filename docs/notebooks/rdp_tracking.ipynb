{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDP - Stone Soup Experiments\n",
    "[Documentation](https://stonesoup.readthedocs.io/en/v1.4/auto_examples/readers/Custom_Pandas_Dataloader.html#sphx-glr-auto-examples-readers-custom-pandas-dataloader-py)\n",
    "\n",
    "Experiments in matching up processes from the Kaggle competition results, Stone Soup samples and C Speed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "from importlib import reload  # Python 3.4+\n",
    "from typing import Tuple\n",
    "import itertools\n",
    "from matplotlib import pyplot as plt\n",
    "from math import ceil\n",
    "\n",
    "import dateutil\n",
    "from pymap3d import geodetic2enu\n",
    "\n",
    "import sys\n",
    "sys.path.append('C:/Users/ttrinter/git_repo/cspeed/data_common')\n",
    "import data_functions as dfunc\n",
    "import visualizations as v\n",
    "# sys.path.append(\"../stonesoup\") # go to parent dir\n",
    "# # from customFunctions import *\n",
    "\n",
    "from stonesoup.reader import DetectionReader, GroundTruthReader\n",
    "from stonesoup.reader.pandas_reader import DataFrameDetectionReader\n",
    "from stonesoup.base import Property\n",
    "from stonesoup.models.transition.linear import CombinedLinearGaussianTransitionModel, \\\n",
    "                                               ConstantVelocity\n",
    "from stonesoup.types.detection import Detection\n",
    "from stonesoup.plotter import AnimatedPlotterly, Plotter, Plotterly\n",
    "\n",
    "from stonesoup.base import Property\n",
    "from stonesoup.buffered_generator import BufferedGenerator\n",
    "from stonesoup.functions import cart2sphere, sphere2cart\n",
    "from stonesoup.models.measurement.linear import LinearGaussian\n",
    "from stonesoup.models.measurement.nonlinear import CartesianToElevationBearingRange, \\\n",
    "    CartesianToBearingRange, Cartesian2DToBearing, CombinedReversibleGaussianMeasurementModel\n",
    "from stonesoup.types.angle import Bearing, Elevation\n",
    "from stonesoup.types.detection import Detection\n",
    "from stonesoup.types.groundtruth import GroundTruthState, GroundTruthPath\n",
    "from stonesoup.types.state import StateVector\n",
    "from stonesoup.plotter import AnimatedPlotterly, Plotter, Plotterly\n",
    "\n",
    "# Tracker Imports\n",
    "from stonesoup.dataassociator.neighbour import GNNWith2DAssignment\n",
    "from stonesoup.deleter.error import CovarianceBasedDeleter\n",
    "from stonesoup.deleter.multi import CompositeDeleter\n",
    "from stonesoup.deleter.time import UpdateTimeDeleter\n",
    "from stonesoup.feeder.multi import MultiDataFeeder\n",
    "from stonesoup.feeder.time import TimeBufferedFeeder\n",
    "from stonesoup.hypothesiser.distance import DistanceHypothesiser\n",
    "from stonesoup.initiator.simple import MultiMeasurementInitiator\n",
    "from stonesoup.measures import Mahalanobis\n",
    "from stonesoup.models.transition.linear import CombinedLinearGaussianTransitionModel, ConstantVelocity\n",
    "from stonesoup.predictor.kalman import ExtendedKalmanPredictor\n",
    "from stonesoup.tracker.simple import MultiTargetTracker\n",
    "from stonesoup.types.array import StateVector, CovarianceMatrix\n",
    "from stonesoup.types.state import GaussianState\n",
    "from stonesoup.updater.kalman import ExtendedKalmanUpdater\n",
    "\n",
    "sensor_positions = { 'RDU103': (51.52126391, 5.85862734)}\n",
    "\n",
    "METERS_in_NM = 1852\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data from BigQuery\n",
    "* rdp_straight: short, straight flight path\n",
    "* rdp_extended: longer flight path\n",
    "* adsb_straight: truth for rdp_straight\n",
    "* adsb_extended: truth for rdp_extended\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_address = 10537421\n",
    "# adsb_sql = f\"\"\"SELECT `timestamp`,\n",
    "#         time_of_day, \n",
    "#         latitude, \n",
    "#         longitude, \n",
    "#         target_address,\n",
    "#         flight_level, \n",
    "#         rho, \n",
    "#         theta\n",
    "# FROM radar_data.adsb\n",
    "# WHERE test_date = '2024-07-17'\n",
    "# AND target_address={target_address}\n",
    "# and latitude is not NULL\n",
    "# AND rho<20\n",
    "# ORDER BY `timestamp`\"\"\"\n",
    "\n",
    "# adsb_straight = dfunc.query_to_df(adsb_sql)\n",
    "\n",
    "# rdp_sql = f\"\"\"SELECT \n",
    "#         `timestamp`,\n",
    "#         time_of_day,\n",
    "#         cal, \n",
    "#         rho,\n",
    "#         theta, \n",
    "#         x, \n",
    "#         y, \n",
    "#         field_note \n",
    "# FROM radar_data.rdp\n",
    "# WHERE `timestamp` >= '{adsb_straight.timestamp.min().strftime(\"%Y-%m-%d %H:%M:%S\")}'\n",
    "# AND `timestamp` <= '{adsb_straight.timestamp.max().strftime(\"%Y-%m-%d %H:%M:%S\")}'\n",
    "# AND rho >= {adsb_straight.rho.min()-0.5}\n",
    "# AND rho <= {adsb_straight.rho.max()+0.5}\n",
    "# AND theta >= {adsb_straight.theta.min()- 5}\n",
    "# AND theta <= {adsb_straight.theta.max()+5}\"\"\"\n",
    "\n",
    "# rdp_straight = dfunc.query_to_df(rdp_sql)\n",
    "# rdp_straight.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save/Read  to/from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi\n",
    "data_dir = 'C:/Users/ttrinter/git_repo/Stone-Soup/data'\n",
    "adsb_file = f'{data_dir}/adsb_straight.csv'\n",
    "# adsb_straight.to_csv(adsb_file, index=False)\n",
    "adsb_data = pd.read_csv(adsb_file)\n",
    "adsb_data['timestamp'] = pd.to_datetime(adsb_data['timestamp'], errors='coerce')\n",
    "adsb_data = adsb_data.loc[~adsb_data['timestamp'].isna()]\n",
    "adsb_data['timestamp'] = pd.to_datetime(adsb_data['timestamp'], errors='coerce')\n",
    "adsb_data['timestamp'] = adsb_data['timestamp'].dt.tz_localize(None)\n",
    "\n",
    "rdp_file = f'{data_dir}/rdp_straight.csv'\n",
    "# rdp_straight['timestamp'] = pd.to_datetime(rdp_straight['timestamp'], errors='coerce')\n",
    "# rdp_straight['theta_rad'] = np.deg2rad(rdp_straight.theta)\n",
    "# rdp_straight.loc[rdp_straight.theta_rad>2*pi, 'theta_rad'] = rdp_straight.loc[rdp_straight.theta_rad>2*pi, 'theta_rad'] - 2*pi \n",
    "\n",
    "# rdp_straight = rdp_straight.loc[~rdp_straight['timestamp'].isna()]\n",
    "# rdp_straight.to_csv(rdp_file, index=False)\n",
    "rdp_data = pd.read_csv(rdp_file)\n",
    "rdp_data['timestamp'] = pd.to_datetime(rdp_data['timestamp'], errors='coerce')\n",
    "rdp_data['timestamp'] = rdp_data['timestamp'].dt.tz_localize(None)\n",
    "\n",
    "# Matched Plots\n",
    "matched_csv = f'{data_dir}/rdp_matched.csv'\n",
    "rdp_matched = pd.read_csv(matched_csv, usecols=range(12))\n",
    "rdp_matched['timestamp'] = pd.to_datetime(rdp_matched['timestamp'], errors='coerce')\n",
    "rdp_matched['timestamp'] = rdp_matched['timestamp'].dt.tz_localize(None)\n",
    "\n",
    "start_time = rdp_matched['timestamp'].min()\n",
    "end_time = rdp_matched['timestamp'].max()\n",
    "\n",
    "print(f'ADSB: {len(adsb_data)}')\n",
    "print(f'RDP: {len(rdp_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matched Data Set\n",
    "To make things even simpler, I'll grab the set of matched data for this test plane. Then most of the plots should be \"true\" detections. Let's see how the tracker does with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = 'C:/Users/ttrinter/OneDrive - cspeed.com (1)/Documents/Data/Travis/2024-07-17'\n",
    "matched_file = '20240717_Travis_matched_rdp_61.xlsx'\n",
    "matched_data = pd.read_excel(f'{file_dir}/{matched_file}')\n",
    "matched_data = matched_data.loc[(matched_data.target_address==target_address) &\n",
    "                                (matched_data.close_enough==True)]\n",
    "matched_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_plot = v.plot_target_match2(matching=matched_data, \n",
    "                                    target_address=target_address, \n",
    "                                    plot_show=True, \n",
    "                                    pd_loc='title')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdp_matched = matched_data[['timestamp_rdp',\n",
    "#                             'cal_rdp',\n",
    "#                             'rho_rdp',\n",
    "#                             'theta_rdp']]\n",
    "\n",
    "# rdp_matched['theta_rad'] = np.deg2rad(rdp_matched.theta_rdp)\n",
    "# # rdp_matched.loc[rdp_matched.theta_rad>2*pi, 'theta_rad'] = rdp_straight.loc[rdp_straight.theta_rad>2*pi, 'theta_rad'] - 2*pi \n",
    "# rdp_matched.rename(columns={'rho_rdp': 'rho',\n",
    "#                             'theta_rdp': 'theta', \n",
    "#                             'timestamp_rdp': 'timestamp', \n",
    "#                             'cal_rdp': 'cal'}, \n",
    "#                             inplace=True)\n",
    "\n",
    "# rdp_matched['x'], rdp_matched['y'] = zip(*rdp_matched.apply(lambda x: dfunc.polar_to_cartesian(x.rho, x.theta), axis=1))\n",
    "\n",
    "# # matched_csv = f'{data_dir}/rdp_matched.csv'\n",
    "# # rdp_matched.to_csv(matched_csv, index=False)\n",
    "\n",
    "# rdp_matched.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdp_matched.plot.scatter(x='x', y='y')\n",
    "plt.grid()\n",
    "plt.title(\"Matched RDP Plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adsb_data.to_csv(adsb_file, index=False)\n",
    "# rdp_data.to_csv(rdp_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'rho: {rdp_data.rho.min()} - {rdp_data.rho.max()}')\n",
    "print(f'theta: {rdp_data.theta.min()} - {rdp_data.theta.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.rad2deg(rdp_data.theta_rad).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Travis Location\n",
    "lat0, lon0, alt0 = 38.25049, -121.92474, 40\n",
    "\n",
    "class RDPReader(DetectionReader):\n",
    "    rdp_file: str = Property(doc=\"File with the radar data.\")\n",
    "    ndim_state: int = Property(default=6)\n",
    "    pos_mapping: Tuple[int, int] = Property(default=(0, 2))\n",
    "    vel_mapping: Tuple[int, int] = Property(default=(1, 3))\n",
    "    pos_noise_diag: Tuple[float, float] = Property(\n",
    "        default=(np.radians(1) ** 2, 25 ** 2))\n",
    "    vel_noise_diag: Tuple[float, float] = Property(default=(1, 1))\n",
    "    min_reflection: float = Property(default=-np.inf)\n",
    "    max_reflection: float = Property(default=35)\n",
    "\n",
    "    # Kaggle Alvira Location\n",
    "    # lat, lon, alt = 51.52126391, 5.85862734, 31\n",
    "\n",
    "    # Travis Radar Location\n",
    "    lat, lon, alt = 38.25049, -121.92474, 40\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        # Kaggle Approach\n",
    "        position_model = CartesianToBearingRange(\n",
    "            self.ndim_state, self.pos_mapping, np.diag(self.pos_noise_diag),\n",
    "            translation_offset=StateVector([*geodetic2enu(self.lat, self.lon, self.alt,\n",
    "                                                          lat0, lon0, alt0)]))\n",
    "        # velocity_model = LinearGaussian(\n",
    "        #     self.ndim_state, self.vel_mapping, np.diag(self.vel_noise_diag))\n",
    "\n",
    "        # self.model = CombinedReversibleGaussianMeasurementModel([position_model, velocity_model])\n",
    "\n",
    "        # Tutorial 6 Approach\n",
    "        # measurement_model = LinearGaussian(\n",
    "        #     ndim_state=4,\n",
    "        #     mapping=(0, 2),\n",
    "        #     noise_covar=np.array([[0.75, 0],\n",
    "        #                         [0, 0.75]])\n",
    "        #     )\n",
    "        \n",
    "        # self.model=measurement_model\n",
    "        self.model=position_model\n",
    "\n",
    "    @BufferedGenerator.generator_method\n",
    "    def detections_gen(self):\n",
    "        with open(self.rdp_file, newline='') as csv_file:\n",
    "            for row in csv.DictReader(csv_file):\n",
    "                if not row['timestamp']:\n",
    "                    continue\n",
    "\n",
    "                timestamp = dateutil.parser.parse(row['timestamp'], ignoretz=True)\n",
    "                # lat = float(row['latitude'])\n",
    "                # lon = float(row['longitude']) \n",
    "                rho = float(row['rho'])*METERS_in_NM\n",
    "                phi = 2*pi - float(row['theta_rad']) + pi/2\n",
    "\n",
    "                # we don't have these usually - commenting out\n",
    "                # azimuth = np.radians(90 - float(row['vtheta']))\n",
    "                # elevation = np.radians(float(row['alt_velocity']))\n",
    "                # speed = float(row['vrho'])\n",
    "                # azimuth = 100\n",
    "                dx = float(row['v_x']) * METERS_in_NM\n",
    "                dy = float(row['v_y']) * METERS_in_NM\n",
    "                elevation = 0\n",
    "                speed = 20\n",
    "\n",
    "                metadata = {\n",
    "                    'cal': row['cal'],\n",
    "                    'sensor': 'RDU103', \n",
    "                    'reflection': 0\n",
    "                    }\n",
    "\n",
    "                if not self.min_reflection < metadata['reflection'] < self.max_reflection:\n",
    "                    continue\n",
    "\n",
    "                # easting, northing, *_ = geodetic2enu(lat, lon, alt, self.lat, self.lon, self.alt)\n",
    "                # rho, phi, _ = cart2sphere(easting, northing, alt)\n",
    "                # dx, dy, dz = sphere2cart(speed, azimuth, elevation)\n",
    "                # dx, dy, dz = 0.5, 0.5, 0\n",
    "\n",
    "                yield timestamp, {Detection(\n",
    "                    [Bearing(phi), rho], timestamp=timestamp,\n",
    "                    # [Bearing(phi), rho, dx, dy], timestamp=timestamp,\n",
    "                    metadata=metadata, measurement_model=self.model)}\n",
    "                \n",
    "class RDPReaderXY(DetectionReader):\n",
    "    rdp_file: str = Property(doc=\"File with the radar data.\")\n",
    "    ndim_state: int = Property(default=6)\n",
    "    # pos_mapping: Tuple[int, int] = Property(default=(0, 2))\n",
    "    pos_mapping: Tuple[int, int] = Property(default=(0, 2))\n",
    "    vel_mapping: Tuple[int, int] = Property(default=(1, 3))\n",
    "\n",
    "    # Travis Radar Location\n",
    "    lat, lon, alt = 38.25049, -121.92474, 40\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        # Tutorial 6 Approach\n",
    "        measurement_model = LinearGaussian(\n",
    "            ndim_state=4,\n",
    "            mapping=(0, 2),\n",
    "            noise_covar=np.array([[0.75, 0],\n",
    "                                [0, 0.75]])\n",
    "            )\n",
    "        \n",
    "        self.model=measurement_model\n",
    "\n",
    "    @BufferedGenerator.generator_method\n",
    "    def detections_gen(self):\n",
    "        with open(self.rdp_file, newline='') as csv_file:\n",
    "            for row in csv.DictReader(csv_file):\n",
    "                if not row['timestamp']:\n",
    "                    continue\n",
    "\n",
    "                timestamp = dateutil.parser.parse(row['timestamp'], ignoretz=True)\n",
    "                # lat = float(row['latitude'])\n",
    "                # lon = float(row['longitude']) \n",
    "                x = float(row['x'])*METERS_in_NM\n",
    "                y = float(row['y'])*METERS_in_NM\n",
    "                dx = float(row['v_x'])*METERS_in_NM\n",
    "                dy = float(row['v_y'])*METERS_in_NM\n",
    "\n",
    "\n",
    "                metadata = {\n",
    "                    'cal': float(row['cal']),\n",
    "                    'sensor': 'RDU103'\n",
    "                    }\n",
    "\n",
    "                yield timestamp, {Detection(\n",
    "                    # [x, dx, y, dy], timestamp=timestamp,\n",
    "                    [x, y], timestamp=timestamp,                \n",
    "                    metadata=metadata, measurement_model=self.model)}\n",
    "                \n",
    "\n",
    "class CSVReaderXY(DetectionReader):\n",
    "    rdp_file: str = Property(doc=\"File with the radar data.\")\n",
    "    ndim_state: int = Property(default=4)\n",
    "    pos_mapping: Tuple[int, int] = Property(default=(0, 2))\n",
    "    # vel_mapping: Tuple[int, int] = Property(default=(1, 3))\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        # Tutorial 6 Approach\n",
    "        measurement_model = LinearGaussian(\n",
    "            ndim_state=4,\n",
    "            mapping=(0, 2),\n",
    "            noise_covar=np.array([[5, 0],\n",
    "                                [0, 5]])\n",
    "            )\n",
    "        \n",
    "        self.model=measurement_model\n",
    "\n",
    "    @BufferedGenerator.generator_method\n",
    "    def detections_gen(self):\n",
    "        with open(self.rdp_file, newline='') as csv_file:\n",
    "            for row in csv.DictReader(csv_file):\n",
    "                if not row['timestamp']:\n",
    "                    continue\n",
    "\n",
    "                timestamp = dateutil.parser.parse(row['timestamp'], ignoretz=True)\n",
    "                # lat = float(row['latitude'])\n",
    "                # lon = float(row['longitude']) \n",
    "                x = float(row['x'])*METERS_in_NM\n",
    "                y = float(row['y'])*METERS_in_NM\n",
    "\n",
    "                yield timestamp, {Detection(\n",
    "                    [x, y], timestamp=timestamp, \n",
    "                    measurement_model=self.model)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ADSBTruthReader(GroundTruthReader):\n",
    "    adsb_file: str = Property(doc=\"File with the adsb data.\")\n",
    "\n",
    "    @staticmethod\n",
    "    def single_ground_truth_reader(adsb_file, isset=True):\n",
    "        truth = GroundTruthPath()\n",
    "        with open(adsb_file, newline='') as csv_file:\n",
    "            for row in csv.DictReader(csv_file):\n",
    "                lat = float(row['latitude'])\n",
    "                lon = float(row['longitude'])\n",
    "                alt = float(row['flight_level'])*100\n",
    "                time = dateutil.parser.parse(row['timestamp'])\n",
    "                if row['target_address'] != \"\":\n",
    "                    planename = row['target_address']\n",
    "                x, y, z = geodetic2enu(lat, lon, alt, lat0, lon0, alt0)\n",
    "                truth.append(GroundTruthState(\n",
    "                    [x, 0, y, 0, z, 0],\n",
    "                    timestamp=time,\n",
    "                    metadata={\"id\": planename}))\n",
    "            if isset:\n",
    "                truth = {truth}\n",
    "        return truth\n",
    "\n",
    "    @classmethod\n",
    "    def multiple_ground_truth_reader(cls, filenames):\n",
    "        truths = set()\n",
    "        for filename in filenames:\n",
    "            truths.add(cls.single_ground_truth_reader(filename, isset=False))\n",
    "        return truths\n",
    "\n",
    "    @BufferedGenerator.generator_method\n",
    "    def groundtruth_paths_gen(self):\n",
    "        truths = self.multiple_ground_truth_reader([adsb_file])\n",
    "        yield None, truths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mimicing code from Kaggle..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_timestamps(start_time, end_time):\n",
    "    total_seconds = (end_time - start_time).total_seconds()\n",
    "    return [start_time + timedelta(seconds=n) for n in range(ceil(total_seconds))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_data.sort_values('timestamp_rdp')[['timestamp_rdp', 'rho_rdp','theta_rdp']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdp = RDPReader(rdp_file,\n",
    "timestamps = generate_timestamps(matched_data.timestamp_rdp.min(), matched_data.timestamp_rdp.max())\n",
    "\n",
    "# Detections\n",
    "meas_csv = CSVReaderXY(matched_csv)\n",
    "\n",
    "# Ground Truth\n",
    "adsb = ADSBTruthReader(adsb_file)\n",
    "ground_truth = set()\n",
    "for time, truths in adsb:\n",
    "    ground_truth.update(truths)\n",
    "\n",
    "dets = [next(iter(detection[1])) for detection in meas_csv.detections_gen()]\n",
    "\n",
    "plotter = AnimatedPlotterly(timestamps, tail_length=0.3, sim_duration=1)\n",
    "\n",
    "#Animated\n",
    "plotter.plot_ground_truths(ground_truth, \n",
    "                           mapping=[0, 2], \n",
    "                           mode='markers', \n",
    "                           marker=dict(color='rgba(0, 0, 255, 0.2)',\n",
    "                                      size=5, \n",
    "                                      symbol=\"square-open\")\n",
    "                            )\n",
    "\n",
    "plotter.plot_measurements(dets,\n",
    "                          mapping=[0, 1],\n",
    "                          measurements_label='Test Data',\n",
    "                          marker=dict(color='rgba(255, 0, 0, 0.7)',\n",
    "                                      size=5, \n",
    "                                      symbol=\"cross\"),\n",
    "                          convert_measurements=False\n",
    ")\n",
    "# plt.title(\"XY Data Sample\")\n",
    "# plt.grid()\n",
    "plotter.fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Tutorial #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stonesoup.models.transition.linear import CombinedLinearGaussianTransitionModel, \\\n",
    "                                               ConstantVelocity\n",
    "from stonesoup.types.groundtruth import GroundTruthPath, GroundTruthState\n",
    "from stonesoup.types.detection import TrueDetection\n",
    "from stonesoup.types.detection import Clutter\n",
    "from stonesoup.models.measurement.linear import LinearGaussian\n",
    "from stonesoup.predictor.kalman import KalmanPredictor\n",
    "from stonesoup.updater.kalman import KalmanUpdater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measurement Model\n",
    "measurement_model = LinearGaussian(\n",
    "    ndim_state=4,   # Number of state dimensions (position and velocity in 2D)\n",
    "    mapping=(0, 2), # Mapping measurement vector index to state index\n",
    "    noise_covar=np.array([[5, 0 ],  \n",
    "                          [0, 5]])\n",
    "    )  #Covariance matrix for Gaussian PDF\n",
    "\n",
    "\n",
    "# Transition Model\n",
    "q_x = -100\n",
    "q_y = 100\n",
    "transition_model = CombinedLinearGaussianTransitionModel([ConstantVelocity(q_x),\n",
    "                                                          ConstantVelocity(q_y)])\n",
    "predictor = KalmanPredictor(transition_model)\n",
    "updater = KalmanUpdater(measurement_model)\n",
    "prior = GaussianState([[90], [-100], [-72], [100]], np.diag([1.5, 0.5, 1.5, 0.5]), timestamp=start_time)\n",
    "\n",
    "start_time = min(timestamps)\n",
    "\n",
    "from stonesoup.types.hypothesis import SingleHypothesis\n",
    "from stonesoup.types.track import Track\n",
    "track = Track()\n",
    "\n",
    "for det in dets:\n",
    "    prediction = predictor.predict(prior, timestamp=det.timestamp)\n",
    "    # print(det.timestamp)\n",
    "    hypothesis = SingleHypothesis(prediction, det)   # Group a prediction and measurement\n",
    "    post = updater.update(hypothesis)\n",
    "    track.append(post)\n",
    "    prior = track[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = AnimatedPlotterly(timestamps, tail_length=.5)\n",
    "\n",
    "plotter.plot_ground_truths(ground_truth, \n",
    "                           mapping=[0, 2], \n",
    "                           mode='markers', \n",
    "                           marker=dict(color='rgba(0, 0, 255, 0.2)',\n",
    "                                      size=5, \n",
    "                                      symbol=\"square-open\")\n",
    "                            )\n",
    "\n",
    "plotter.plot_tracks(track, [0, 2], uncertainty=True)\n",
    "\n",
    "plotter.plot_measurements(dets,\n",
    "                          mapping=[0, 2],\n",
    "                          measurements_label='Test Data',\n",
    "                          marker=dict(color='rgba(255, 0, 0, 0.7)',\n",
    "                                      size=5, \n",
    "                                      symbol=\"cross\"))\n",
    "\n",
    "plotter.fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asterix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

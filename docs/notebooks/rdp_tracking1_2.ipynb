{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDP - Stone Soup Experiments\n",
    "[Documentation](https://stonesoup.readthedocs.io/en/v1.4/auto_examples/readers/Custom_Pandas_Dataloader.html#sphx-glr-auto-examples-readers-custom-pandas-dataloader-py)\n",
    "\n",
    "Stone Soup tutorials 1 & 2 with data reader code from Kaggle.\n",
    "* Tutorial 1: Kalman Filter\n",
    "* Tutorial 2: Extended Kalman Filter for non-linear models (using polar coordinates instead of cartesian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from datetime import timedelta\n",
    "from importlib import reload  # Python 3.4+\n",
    "from typing import Tuple\n",
    "from matplotlib import pyplot as plt\n",
    "from math import ceil, pi\n",
    "\n",
    "\n",
    "import dateutil\n",
    "from pymap3d import geodetic2enu\n",
    "\n",
    "import sys\n",
    "sys.path.append('C:/Users/ttrinter/git_repo/cspeed/data_common')\n",
    "sys.path.append('../../..')\n",
    "import data_functions as dfunc\n",
    "import visualizations as v\n",
    "from ttt_ss_funcs import generate_timestamps, ADSBTruthReader, CSVReaderXY, CSVReaderPolar, plot_all\n",
    "# sys.path.append(\"../stonesoup\") # go to parent dir\n",
    "# # from customFunctions import *\n",
    "\n",
    "from stonesoup.reader import DetectionReader, GroundTruthReader\n",
    "from stonesoup.base import Property\n",
    "from stonesoup.types.detection import Detection\n",
    "from stonesoup.plotter import AnimatedPlotterly\n",
    "\n",
    "from stonesoup.base import Property\n",
    "from stonesoup.buffered_generator import BufferedGenerator\n",
    "from stonesoup.functions import cart2sphere, sphere2cart\n",
    "from stonesoup.models.measurement.linear import LinearGaussian\n",
    "from stonesoup.models.measurement.nonlinear import CartesianToBearingRange\n",
    "from stonesoup.types.angle import Bearing\n",
    "from stonesoup.types.detection import Detection\n",
    "from stonesoup.types.groundtruth import GroundTruthState, GroundTruthPath\n",
    "from stonesoup.plotter import AnimatedPlotterly, Plotter, Plotterly\n",
    "\n",
    "# Tracker Imports\n",
    "from stonesoup.types.state import GaussianState\n",
    "sensor_positions = { 'RDU103': (51.52126391, 5.85862734)}\n",
    "\n",
    "METERS_in_NM = 1852"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data from BigQuery\n",
    "* rdp_straight: short, straight flight path\n",
    "* rdp_extended: longer flight path\n",
    "* adsb_straight: truth for rdp_straight\n",
    "* adsb_extended: truth for rdp_extended\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_address = 10537421\n",
    "# adsb_sql = f\"\"\"SELECT `timestamp`,\n",
    "#         time_of_day, \n",
    "#         latitude, \n",
    "#         longitude, \n",
    "#         target_address,\n",
    "#         flight_level, \n",
    "#         rho, \n",
    "#         theta\n",
    "# FROM radar_data.adsb\n",
    "# WHERE test_date = '2024-07-17'\n",
    "# AND target_address={target_address}\n",
    "# and latitude is not NULL\n",
    "# AND rho<20\n",
    "# ORDER BY `timestamp`\"\"\"\n",
    "\n",
    "# adsb_straight = dfunc.query_to_df(adsb_sql)\n",
    "\n",
    "# rdp_sql = f\"\"\"SELECT \n",
    "#         `timestamp`,\n",
    "#         time_of_day,\n",
    "#         cal, \n",
    "#         rho,\n",
    "#         theta, \n",
    "#         x, \n",
    "#         y, \n",
    "#         field_note \n",
    "# FROM radar_data.rdp\n",
    "# WHERE `timestamp` >= '{adsb_straight.timestamp.min().strftime(\"%Y-%m-%d %H:%M:%S\")}'\n",
    "# AND `timestamp` <= '{adsb_straight.timestamp.max().strftime(\"%Y-%m-%d %H:%M:%S\")}'\n",
    "# AND sortie_id=61\n",
    "# AND rho >= {adsb_straight.rho.min()-0.5}\n",
    "# AND rho <= {adsb_straight.rho.max()+0.5}\n",
    "# AND theta >= {adsb_straight.theta.min()- 5}\n",
    "# AND theta <= {adsb_straight.theta.max()+5}\"\"\"\n",
    "\n",
    "# rdp_straight = dfunc.query_to_df(rdp_sql)\n",
    "# rdp_straight.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save/Read  to/from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'C:/Users/ttrinter/git_repo/Stone-Soup/data'\n",
    "adsb_file = f'{data_dir}/adsb_straight.csv'\n",
    "# adsb_straight.to_csv(adsb_file, index=False)\n",
    "adsb_data = pd.read_csv(adsb_file)\n",
    "\n",
    "adsb_data['timestamp'] = pd.to_datetime(adsb_data['timestamp'], errors='coerce')\n",
    "adsb_data = adsb_data.loc[~adsb_data['timestamp'].isna()]\n",
    "adsb_data['timestamp'] = pd.to_datetime(adsb_data['timestamp'], errors='coerce')\n",
    "adsb_data['timestamp'] = adsb_data['timestamp'].dt.tz_localize(None)\n",
    "adsb_data['timestamp'] = adsb_data['timestamp'].astype('datetime64[us]')\n",
    "\n",
    "rdp_file = f'{data_dir}/rdp_straight.csv'\n",
    "# rdp_straight['timestamp'] = pd.to_datetime(rdp_straight['timestamp'], errors='coerce')\n",
    "# rdp_straight['theta_rad'] = np.deg2rad(rdp_straight.theta)\n",
    "# rdp_straight.loc[rdp_straight.theta_rad>2*pi, 'theta_rad'] = rdp_straight.loc[rdp_straight.theta_rad>2*pi, 'theta_rad'] - 2*pi \n",
    "\n",
    "# rdp_straight = rdp_straight.loc[~rdp_straight['timestamp'].isna()]\n",
    "# rdp_straight.to_csv(rdp_file, index=False)\n",
    "rdp_data = pd.read_csv(rdp_file)\n",
    "rdp_data['timestamp'] = pd.to_datetime(rdp_data['timestamp'], errors='coerce')\n",
    "rdp_data['timestamp'] = rdp_data['timestamp'].dt.tz_localize(None)\n",
    "rdp_data['timestamp'] = rdp_data['timestamp'].astype('datetime64[us]')\n",
    "\n",
    "# Matched Plots\n",
    "matched_csv = f'{data_dir}/rdp_matched.csv'\n",
    "rdp_matched = pd.read_csv(matched_csv)\n",
    "rdp_matched['timestamp'] = pd.to_datetime(rdp_matched['timestamp'], errors='coerce')\n",
    "rdp_matched['timestamp'] = rdp_matched['timestamp'].dt.tz_localize(None)\n",
    "rdp_matched['timestamp'] = rdp_matched['timestamp'].astype('datetime64[us]')\n",
    "\n",
    "start_time = rdp_matched['timestamp'].min()\n",
    "end_time = rdp_matched['timestamp'].max()\n",
    "\n",
    "print(f'ADSB: {len(adsb_data)}')\n",
    "print(f'RDP: {len(rdp_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matched Data Set\n",
    "To make things even simpler, I'll grab the set of matched data for this test plane. Then most of the plots should be \"true\" detections. Let's see how the tracker does with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = 'C:/Users/ttrinter/OneDrive - cspeed.com (1)/Documents/Data/Travis/2024-07-17'\n",
    "matched_file = '20240717_Travis_matched_rdp_61.xlsx'\n",
    "matched_data = pd.read_excel(f'{file_dir}/{matched_file}')\n",
    "matched_data = matched_data.loc[(matched_data.target_address==target_address) &\n",
    "                                (matched_data.close_enough==True)]\n",
    "matched_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_plot = v.plot_target_match2(matching=matched_data, \n",
    "                                    target_address=target_address, \n",
    "                                    plot_show=True, \n",
    "                                    pd_loc='title')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdp_matched = matched_data[['timestamp_rdp',\n",
    "#                             'cal_rdp',\n",
    "#                             'rho_rdp',\n",
    "#                             'theta_rdp']]\n",
    "\n",
    "# rdp_matched['theta_rad'] = np.deg2rad(rdp_matched.theta_rdp)\n",
    "# # rdp_matched.loc[rdp_matched.theta_rad>2*pi, 'theta_rad'] = rdp_straight.loc[rdp_straight.theta_rad>2*pi, 'theta_rad'] - 2*pi \n",
    "# rdp_matched.rename(columns={'rho_rdp': 'rho',\n",
    "#                             'theta_rdp': 'theta', \n",
    "#                             'timestamp_rdp': 'timestamp', \n",
    "#                             'cal_rdp': 'cal'}, \n",
    "#                             inplace=True)\n",
    "\n",
    "# rdp_matched['x'], rdp_matched['y'] = zip(*rdp_matched.apply(lambda x: dfunc.polar_to_cartesian(x.rho, x.theta), axis=1))\n",
    "\n",
    "# # matched_csv = f'{data_dir}/rdp_matched.csv'\n",
    "# # rdp_matched.to_csv(matched_csv, index=False)\n",
    "\n",
    "# rdp_matched.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdp_matched.plot.scatter(x='x', y='y')\n",
    "plt.grid()\n",
    "plt.title(\"Matched RDP Plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adsb_data.to_csv(adsb_file, index=False)\n",
    "# rdp_data.to_csv(rdp_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'rho: {rdp_data.rho.min()} - {rdp_data.rho.max()}')\n",
    "print(f'theta: {rdp_data.theta.min()} - {rdp_data.theta.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.rad2deg(rdp_data.theta_rad).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Travis Location\n",
    "# lat0, lon0, alt0 = 38.25049, -121.92474, 40\n",
    "\n",
    "# class CSVReaderXY(DetectionReader):\n",
    "#     rdp_file: str = Property(doc=\"File with the radar data.\")\n",
    "#     ndim_state: int = Property(default=4)\n",
    "#     pos_mapping: Tuple[int, int] = Property(default=(0, 2))\n",
    "#     # vel_mapping: Tuple[int, int] = Property(default=(1, 3))\n",
    "\n",
    "#     def __init__(self, *args, **kwargs):\n",
    "#         super().__init__(*args, **kwargs)\n",
    "\n",
    "#         # Tutorial 6 Approach\n",
    "#         measurement_model = LinearGaussian(\n",
    "#             ndim_state=4,\n",
    "#             mapping=(0, 2),\n",
    "#             noise_covar=np.array([[5, 0],\n",
    "#                                 [0, 5]])\n",
    "#             )\n",
    "        \n",
    "#         self.model=measurement_model\n",
    "\n",
    "#     @BufferedGenerator.generator_method\n",
    "#     def detections_gen(self):\n",
    "#         with open(self.rdp_file, newline='') as csv_file:\n",
    "#             for row in csv.DictReader(csv_file):\n",
    "#                 if not row['timestamp']:\n",
    "#                     continue\n",
    "\n",
    "#                 timestamp = dateutil.parser.parse(row['timestamp'], ignoretz=True)\n",
    "#                 # lat = float(row['latitude'])\n",
    "#                 # lon = float(row['longitude']) \n",
    "#                 x = float(row['x'])*METERS_in_NM\n",
    "#                 y = float(row['y'])*METERS_in_NM\n",
    "\n",
    "#                 yield timestamp, {Detection(\n",
    "#                     [x, y], timestamp=timestamp, \n",
    "#                     measurement_model=self.model)}\n",
    "\n",
    "\n",
    "# class CSVReaderPolar(DetectionReader):\n",
    "#     rdp_file: str = Property(doc=\"File with the radar data.\")\n",
    "#     ndim_state: int = Property(default=4)\n",
    "#     pos_mapping: Tuple[int, int] = Property(default=(0, 2))\n",
    "\n",
    "#     def __init__(self, *args, **kwargs):\n",
    "#         super().__init__(*args, **kwargs)\n",
    "\n",
    "#         # Kaggle Approach\n",
    "#         measurement_model = CartesianToBearingRange(ndim_state=self.ndim_state, \n",
    "#                                                  mapping=self.pos_mapping, \n",
    "#                                                  noise_covar=np.diag([np.radians(0.2), 1]))\n",
    "        \n",
    "#         self.model=measurement_model\n",
    "\n",
    "\n",
    "#     @BufferedGenerator.generator_method\n",
    "#     def detections_gen(self):\n",
    "#         with open(self.rdp_file, newline='') as csv_file:\n",
    "#             for row in csv.DictReader(csv_file):\n",
    "#                 if not row['timestamp']:\n",
    "#                     continue\n",
    "\n",
    "#                 timestamp = dateutil.parser.parse(row['timestamp'], ignoretz=True)\n",
    "#                 rho = float(row['rho'])*METERS_in_NM\n",
    "#                 phi = 2*pi - float(row['theta_rad']) + pi/2\n",
    "\n",
    "#                 metadata = {\n",
    "#                     'cal': float(row['cal']),\n",
    "#                     'sensor': 'RDU103'\n",
    "#                     }\n",
    "\n",
    "#                 yield timestamp, {Detection(\n",
    "#                     [Bearing(phi), rho], timestamp=timestamp,\n",
    "#                     # [Bearing(phi), rho, dx, dy], timestamp=timestamp,\n",
    "#                     metadata=metadata, measurement_model=self.model)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ADSBTruthReader(GroundTruthReader):\n",
    "#     adsb_file: str = Property(doc=\"File with the adsb data.\")\n",
    "\n",
    "#     @staticmethod\n",
    "#     def single_ground_truth_reader(adsb_file, isset=True):\n",
    "#         truth = GroundTruthPath()\n",
    "#         with open(adsb_file, newline='') as csv_file:\n",
    "#             for row in csv.DictReader(csv_file):\n",
    "#                 lat = float(row['latitude'])\n",
    "#                 lon = float(row['longitude'])\n",
    "#                 alt = float(row['flight_level'])*100\n",
    "#                 time = dateutil.parser.parse(row['timestamp'])\n",
    "#                 if row['target_address'] != \"\":\n",
    "#                     planename = row['target_address']\n",
    "#                 x, y, z = geodetic2enu(lat, lon, alt, lat0, lon0, alt0)\n",
    "#                 truth.append(GroundTruthState(\n",
    "#                     [x, 0, y, 0, z, 0],\n",
    "#                     timestamp=time,\n",
    "#                     metadata={\"id\": planename}))\n",
    "#             if isset:\n",
    "#                 truth = {truth}\n",
    "#         return truth\n",
    "\n",
    "#     @classmethod\n",
    "#     def multiple_ground_truth_reader(cls, filenames):\n",
    "#         truths = set()\n",
    "#         for filename in filenames:\n",
    "#             truths.add(cls.single_ground_truth_reader(filename, isset=False))\n",
    "#         return truths\n",
    "\n",
    "#     @BufferedGenerator.generator_method\n",
    "#     def groundtruth_paths_gen(self):\n",
    "#         truths = self.multiple_ground_truth_reader([adsb_file])\n",
    "#         yield None, truths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mimicing code from Kaggle..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_timestamps(start_time, end_time):\n",
    "#     total_seconds = (end_time - start_time).total_seconds()\n",
    "#     return [start_time + timedelta(seconds=n) for n in range(ceil(total_seconds))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_data.sort_values('timestamp_rdp')[['timestamp_rdp', 'rho_rdp','theta_rdp']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detections\n",
    "matched_xy = CSVReaderXY(matched_csv)\n",
    "matched_polar = CSVReaderPolar(matched_csv)\n",
    "\n",
    "# ADSB\n",
    "adsb = ADSBTruthReader.multiple_ground_truth_reader([adsb_file])\n",
    "\n",
    "dets = [next(iter(detection[1])) for detection in matched_xy.detections_gen()]\n",
    "\n",
    "timestamps = generate_timestamps(start_time, end_time)\n",
    "plot_all(dets, adsb, start_time, end_time, plot_type='animated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Tutorial #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stonesoup.models.transition.linear import CombinedLinearGaussianTransitionModel, \\\n",
    "                                               ConstantVelocity\n",
    "from stonesoup.models.measurement.linear import LinearGaussian\n",
    "from stonesoup.predictor.kalman import KalmanPredictor, ExtendedKalmanPredictor \n",
    "from stonesoup.updater.kalman import KalmanUpdater, ExtendedKalmanUpdater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measurement Model\n",
    "measurement_model = LinearGaussian(\n",
    "    ndim_state=4,   # Number of state dimensions (position and velocity in 2D)\n",
    "    mapping=(0, 2), # Mapping measurement vector index to state index\n",
    "    noise_covar=np.array([[5, 0 ],  \n",
    "                          [0, 5]])\n",
    "    )  #Covariance matrix for Gaussian PDF\n",
    "\n",
    "\n",
    "# Transition Model\n",
    "q_const = 50\n",
    "q_x = q_const\n",
    "q_y = q_const\n",
    "\n",
    "transition_model = CombinedLinearGaussianTransitionModel([ConstantVelocity(q_x),\n",
    "                                                          ConstantVelocity(q_y)])\n",
    "predictor = KalmanPredictor(transition_model)\n",
    "updater = KalmanUpdater(measurement_model)\n",
    "\n",
    "# Set Prior for the known track\n",
    "# using the known starting values\n",
    "# prior = GaussianState([[90], [-100], [-72], [100]], np.diag([1.5, 0.5, 1.5, 0.5]), timestamp=start_time)\n",
    "\n",
    "# using the location of the radar\n",
    "prior = GaussianState([[0], [50], [0], [50]], np.diag([1.5, 0.5, 1.5, 0.5]), timestamp=start_time)\n",
    "\n",
    "\n",
    "start_time = min(timestamps)\n",
    "\n",
    "from stonesoup.types.hypothesis import SingleHypothesis\n",
    "from stonesoup.types.track import Track\n",
    "track = Track()\n",
    "\n",
    "for det in dets:\n",
    "    prediction = predictor.predict(prior, timestamp=det.timestamp)\n",
    "    # print(det.timestamp)\n",
    "    hypothesis = SingleHypothesis(prediction, det)   # Group a prediction and measurement\n",
    "    post = updater.update(hypothesis)\n",
    "    track.append(post)\n",
    "    prior = track[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_all(dets, adsb, start_time, end_time, q_const, track, plot_type='animated')\n",
    "plot_all(dets, adsb, start_time, end_time, q_const, track, plot_type='static')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the starting prior didn't change the results much at all - so not very sensitive to that! However, the first track point is always oddly somewhere between the radar and the actual first observation. Maybe this will clean up in later iterations of the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polar Coordinates\n",
    "Trying again, but changing the process to read rho and theta and, maybe later also radial velocity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detections\n",
    "meas_polar = CSVReaderPolar(matched_csv)\n",
    "dets = [next(iter(detection[1])) for detection in meas_polar.detections_gen()]\n",
    "\n",
    "plot_all(dets, adsb, start_time, end_time, plot_type='animated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kalman Filtering Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stonesoup.models.measurement.nonlinear import CartesianToBearingRange\n",
    "from stonesoup.updater.kalman import ExtendedKalmanUpdater\n",
    "from stonesoup.models.transition.linear import ConstantVelocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_model = CartesianToBearingRange(ndim_state=4, \n",
    "                                            mapping=(0,2), \n",
    "                                            noise_covar=np.diag([np.radians(0.2), 1])\n",
    "                                            )\n",
    "\n",
    "transition_model = CombinedLinearGaussianTransitionModel([ConstantVelocity(q_x),\n",
    "                                                          ConstantVelocity(q_y)])\n",
    "\n",
    "predictor = ExtendedKalmanPredictor(transition_model)\n",
    "\n",
    "updater = ExtendedKalmanUpdater(measurement_model)\n",
    "\n",
    "from stonesoup.types.state import GaussianState\n",
    "prior = GaussianState([[90], [-100], [-72], [100]], np.diag([10, 0.5, 10, 0.5]), timestamp=start_time)\n",
    "# prior = GaussianState([[0], [10], [0], [10]], np.diag([10, 0.5, 10, 0.5]), timestamp=start_time)\n",
    "\n",
    "from stonesoup.types.hypothesis import SingleHypothesis\n",
    "from stonesoup.types.track import Track\n",
    "\n",
    "track = Track()\n",
    "for measurement in dets:\n",
    "    prediction = predictor.predict(prior, timestamp=measurement.timestamp)\n",
    "    hypothesis = SingleHypothesis(prediction, measurement)  # Group a prediction and measurement\n",
    "    post = updater.update(hypothesis)\n",
    "    track.append(post)\n",
    "    prior = track[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_all(dets, adsb, start_time, end_time, q_const, track, plot_type='animated')\n",
    "plot_all(dets, adsb, start_time, end_time, q_const, track, plot_type='static')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asterix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

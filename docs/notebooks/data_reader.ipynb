{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stone Soup Data Reader\n",
    "[Documentation](https://stonesoup.readthedocs.io/en/v1.4/auto_examples/readers/Custom_Pandas_Dataloader.html#sphx-glr-auto-examples-readers-custom-pandas-dataloader-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "from importlib import reload  # Python 3.4+\n",
    "from typing import Tuple\n",
    "import itertools\n",
    "from matplotlib import pyplot as plt\n",
    "from math import ceil\n",
    "\n",
    "import dateutil\n",
    "from pymap3d import geodetic2enu\n",
    "\n",
    "import sys\n",
    "sys.path.append('C:/Users/ttrinter/git_repo/cspeed/data_common')\n",
    "import data_functions as dfunc\n",
    "# sys.path.append(\"../stonesoup\") # go to parent dir\n",
    "# # from customFunctions import *\n",
    "\n",
    "from stonesoup.reader import DetectionReader, GroundTruthReader\n",
    "from stonesoup.reader.pandas_reader import DataFrameDetectionReader\n",
    "from stonesoup.base import Property\n",
    "from stonesoup.models.transition.linear import CombinedLinearGaussianTransitionModel, \\\n",
    "                                               ConstantVelocity\n",
    "from stonesoup.types.detection import Detection\n",
    "from stonesoup.plotter import AnimatedPlotterly, Plotter, Plotterly\n",
    "\n",
    "from stonesoup.base import Property\n",
    "from stonesoup.buffered_generator import BufferedGenerator\n",
    "from stonesoup.functions import cart2sphere, sphere2cart\n",
    "from stonesoup.models.measurement.linear import LinearGaussian\n",
    "from stonesoup.models.measurement.nonlinear import CartesianToElevationBearingRange, \\\n",
    "    CartesianToBearingRange, Cartesian2DToBearing, CombinedReversibleGaussianMeasurementModel\n",
    "from stonesoup.types.angle import Bearing, Elevation\n",
    "from stonesoup.types.detection import Detection\n",
    "from stonesoup.types.groundtruth import GroundTruthState, GroundTruthPath\n",
    "from stonesoup.types.state import StateVector\n",
    "from stonesoup.plotter import AnimatedPlotterly, Plotter, Plotterly\n",
    "\n",
    "# Tracker Imports\n",
    "from stonesoup.dataassociator.neighbour import GNNWith2DAssignment\n",
    "from stonesoup.deleter.error import CovarianceBasedDeleter\n",
    "from stonesoup.deleter.multi import CompositeDeleter\n",
    "from stonesoup.deleter.time import UpdateTimeDeleter\n",
    "from stonesoup.feeder.multi import MultiDataFeeder\n",
    "from stonesoup.feeder.time import TimeBufferedFeeder\n",
    "from stonesoup.hypothesiser.distance import DistanceHypothesiser\n",
    "from stonesoup.initiator.simple import MultiMeasurementInitiator\n",
    "from stonesoup.measures import Mahalanobis\n",
    "from stonesoup.models.transition.linear import CombinedLinearGaussianTransitionModel, ConstantVelocity\n",
    "from stonesoup.predictor.kalman import ExtendedKalmanPredictor\n",
    "from stonesoup.tracker.simple import MultiTargetTracker\n",
    "from stonesoup.types.array import StateVector, CovarianceMatrix\n",
    "from stonesoup.types.state import GaussianState\n",
    "from stonesoup.updater.kalman import ExtendedKalmanUpdater\n",
    "\n",
    "sensor_positions = { 'RDU103': (51.52126391, 5.85862734)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data from BigQuery\n",
    "* rdp_straight: short, straight flight path\n",
    "* rdp_extended: longer flight path\n",
    "* adsb_straight: truth for rdp_straight\n",
    "* adsb_extended: truth for rdp_extended\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adsb_sql = \"\"\"SELECT `timestamp`,\n",
    "#         time_of_day, \n",
    "#         latitude, \n",
    "#         longitude, \n",
    "#         target_address,\n",
    "#         flight_level, \n",
    "#         rho, \n",
    "#         theta\n",
    "# FROM radar_data.adsb\n",
    "# WHERE test_date = '2024-07-17'\n",
    "# AND target_address=10537421\n",
    "# and latitude is not NULL\n",
    "# AND rho<20\n",
    "# ORDER BY `timestamp`\"\"\"\n",
    "\n",
    "# adsb_straight = dfunc.query_to_df(adsb_sql)\n",
    "\n",
    "# rdp_sql = f\"\"\"SELECT \n",
    "#         `timestamp`,\n",
    "#         time_of_day,\n",
    "#         cal, \n",
    "#         rho,\n",
    "#         theta, \n",
    "#         x, \n",
    "#         y, \n",
    "#         field_note \n",
    "# FROM radar_data.rdp\n",
    "# WHERE `timestamp` >= '{adsb_straight.timestamp.min().strftime(\"%Y-%m-%d %H:%M:%S\")}'\n",
    "# AND `timestamp` <= '{adsb_straight.timestamp.max().strftime(\"%Y-%m-%d %H:%M:%S\")}'\n",
    "# AND rho >= {adsb_straight.rho.min()-0.5}\n",
    "# AND rho <= {adsb_straight.rho.max()+0.5}\n",
    "# AND theta >= {adsb_straight.theta.min()- 5}\n",
    "# AND theta <= {adsb_straight.theta.max()+5}\"\"\"\n",
    "\n",
    "# rdp_straight = dfunc.query_to_df(rdp_sql)\n",
    "# rdp_straight.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save/Read  to/from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi\n",
    "data_dir = 'C:/Users/ttrinter/git_repo/Stone-Soup/data'\n",
    "adsb_file = f'{data_dir}/adsb_straight.csv'\n",
    "# adsb_straight.to_csv(adsb_file, index=False)\n",
    "adsb_data = pd.read_csv(adsb_file)\n",
    "adsb_data['timestamp'] = pd.to_datetime(adsb_data['timestamp'], errors='coerce')\n",
    "adsb_data = adsb_data.loc[~adsb_data['timestamp'].isna()]\n",
    "adsb_data['timestamp'] = pd.to_datetime(adsb_data['timestamp'], errors='coerce')\n",
    "adsb_data['timestamp'] = adsb_data['timestamp'].dt.tz_localize(None)\n",
    "\n",
    "rdp_file = f'{data_dir}/rdp_straight.csv'\n",
    "# rdp_straight['timestamp'] = pd.to_datetime(rdp_straight['timestamp'], errors='coerce')\n",
    "# rdp_straight['theta_rad'] = np.deg2rad(rdp_straight.theta)\n",
    "# rdp_straight.loc[rdp_straight.theta_rad>2*pi, 'theta_rad'] = rdp_straight.loc[rdp_straight.theta_rad>2*pi, 'theta_rad'] - 2*pi \n",
    "\n",
    "# rdp_straight = rdp_straight.loc[~rdp_straight['timestamp'].isna()]\n",
    "# rdp_straight.to_csv(rdp_file, index=False)\n",
    "rdp_data = pd.read_csv(rdp_file)\n",
    "rdp_data['timestamp'] = pd.to_datetime(rdp_data['timestamp'], errors='coerce')\n",
    "rdp_data['timestamp'] = rdp_data['timestamp'].dt.tz_localize(None)\n",
    "\n",
    "\n",
    "print(f'ADSB: {len(adsb_data)}')\n",
    "print(f'RDP: {len(rdp_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adsb_data.to_csv(adsb_file, index=False)\n",
    "# rdp_data.to_csv(rdp_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'rho: {rdp_data.rho.min()} - {rdp_data.rho.max()}')\n",
    "print(f'theta: {rdp_data.theta.min()} - {rdp_data.theta.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.rad2deg(rdp_data.theta_rad).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat0, lon0, alt0 = 38.25049, -121.92474, 40\n",
    "\n",
    "class RDPReader(DetectionReader):\n",
    "    rdp_file: str = Property(doc=\"File with the radar data.\")\n",
    "    ndim_state: int = Property(default=6)\n",
    "    pos_mapping: Tuple[int, int] = Property(default=(0, 2))\n",
    "    vel_mapping: Tuple[int, int] = Property(default=(1, 3))\n",
    "    pos_noise_diag: Tuple[float, float] = Property(\n",
    "        default=(np.radians(1) ** 2, 25 ** 2))\n",
    "    vel_noise_diag: Tuple[float, float] = Property(default=(1, 1))\n",
    "    min_reflection: float = Property(default=-np.inf)\n",
    "    max_reflection: float = Property(default=35)\n",
    "\n",
    "    # Kaggle Alvira Location\n",
    "    # lat, lon, alt = 51.52126391, 5.85862734, 31\n",
    "\n",
    "    # Travis Radar Location\n",
    "    lat, lon, alt = 38.25049, -121.92474, 40\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        position_model = CartesianToBearingRange(\n",
    "            self.ndim_state, self.pos_mapping, np.diag(self.pos_noise_diag),\n",
    "            translation_offset=StateVector([*geodetic2enu(self.lat, self.lon, self.alt,\n",
    "                                                          lat0, lon0, alt0)]))\n",
    "        velocity_model = LinearGaussian(\n",
    "            self.ndim_state, self.vel_mapping, np.diag(self.vel_noise_diag))\n",
    "\n",
    "        self.model = CombinedReversibleGaussianMeasurementModel([position_model, velocity_model])\n",
    "\n",
    "    @BufferedGenerator.generator_method\n",
    "    def detections_gen(self):\n",
    "        with open(self.rdp_file, newline='') as csv_file:\n",
    "            for row in csv.DictReader(csv_file):\n",
    "                if not row['timestamp']:\n",
    "                    continue\n",
    "\n",
    "                timestamp = dateutil.parser.parse(row['timestamp'], ignoretz=True)\n",
    "                # lat = float(row['latitude'])\n",
    "                # lon = float(row['longitude']) \n",
    "                rho = float(row['rho'])*METERS_in_NM\n",
    "                phi = 2*pi - float(row['theta_rad']) + pi/2\n",
    "\n",
    "                # we don't have these usually - commenting out\n",
    "                # azimuth = np.radians(90 - float(row['az_velocity']))\n",
    "                # elevation = np.radians(float(row['alt_velocity']))\n",
    "                # speed = float(row['speed'])\n",
    "                azimuth = 100\n",
    "                elevation = 0\n",
    "                speed = 20\n",
    "\n",
    "                metadata = {\n",
    "                    'cal': row['cal'],\n",
    "                    'sensor': 'RDU103', \n",
    "                    'reflection': 0\n",
    "                    }\n",
    "\n",
    "                if not self.min_reflection < metadata['reflection'] < self.max_reflection:\n",
    "                    continue\n",
    "\n",
    "                # easting, northing, *_ = geodetic2enu(lat, lon, alt, self.lat, self.lon, self.alt)\n",
    "                # rho, phi, _ = cart2sphere(easting, northing, alt)\n",
    "                dx, dy, dz = sphere2cart(speed, azimuth, elevation)\n",
    "                # dx, dy, dz = 0.5, 0.5, 0\n",
    "\n",
    "                yield timestamp, {Detection(\n",
    "                    # [Bearing(phi), rho], timestamp=timestamp,\n",
    "                    [Bearing(phi), rho, dx, dy], timestamp=timestamp,\n",
    "                    metadata=metadata, measurement_model=self.model)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ADSBTruthReader(GroundTruthReader):\n",
    "    adsb_file: str = Property(doc=\"File with the adsb data.\")\n",
    "\n",
    "    @staticmethod\n",
    "    def single_ground_truth_reader(adsb_file, isset=True):\n",
    "        truth = GroundTruthPath()\n",
    "        with open(adsb_file, newline='') as csv_file:\n",
    "            for row in csv.DictReader(csv_file):\n",
    "                lat = float(row['latitude'])\n",
    "                lon = float(row['longitude'])\n",
    "                alt = float(row['flight_level'])*100\n",
    "                time = dateutil.parser.parse(row['timestamp'])\n",
    "                if row['target_address'] != \"\":\n",
    "                    planename = row['target_address']\n",
    "                x, y, z = geodetic2enu(lat, lon, alt, lat0, lon0, alt0)\n",
    "                truth.append(GroundTruthState(\n",
    "                    [x, 0, y, 0, z, 0],\n",
    "                    timestamp=time,\n",
    "                    metadata={\"id\": planename}))\n",
    "            if isset:\n",
    "                truth = {truth}\n",
    "        return truth\n",
    "\n",
    "    @classmethod\n",
    "    def multiple_ground_truth_reader(cls, filenames):\n",
    "        truths = set()\n",
    "        for filename in filenames:\n",
    "            truths.add(cls.single_ground_truth_reader(filename, isset=False))\n",
    "        return truths\n",
    "\n",
    "    @BufferedGenerator.generator_method\n",
    "    def groundtruth_paths_gen(self):\n",
    "        truths = self.multiple_ground_truth_reader([adsb_file])\n",
    "        yield None, truths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mimicing code from Kaggle..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ALVIRAReader_mod(DetectionReader):\n",
    "    filename: str = Property(doc=\"Folder where scenario file is.\")\n",
    "    ndim_state: int = Property(default=6)\n",
    "    pos_mapping: Tuple[int, int] = Property(default=(0, 2))\n",
    "    vel_mapping: Tuple[int, int] = Property(default=(1, 3))\n",
    "    pos_noise_diag: Tuple[float, float] = Property(\n",
    "        default=(np.radians(1) ** 2, 25 ** 2))\n",
    "    vel_noise_diag: Tuple[float, float] = Property(default=(1, 1))\n",
    "    min_reflection: float = Property(default=-np.inf)\n",
    "    max_reflection: float = Property(default=35)\n",
    "\n",
    "    lat, lon, alt = 51.52126391, 5.85862734, 31\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        position_model = CartesianToBearingRange(\n",
    "            self.ndim_state, self.pos_mapping, np.diag(self.pos_noise_diag),\n",
    "            translation_offset=StateVector([*geodetic2enu(self.lat, self.lon, self.alt,\n",
    "                                                          lat0, lon0, alt0)]))\n",
    "        velocity_model = LinearGaussian(\n",
    "            self.ndim_state, self.vel_mapping, np.diag(self.vel_noise_diag))\n",
    "\n",
    "        self.model = CombinedReversibleGaussianMeasurementModel([position_model, velocity_model])\n",
    "\n",
    "    @BufferedGenerator.generator_method\n",
    "    def detections_gen(self):\n",
    "        with open(self.filename, newline='') as csv_file:\n",
    "            for row in csv.DictReader(csv_file):\n",
    "                if not row['timestamp']:\n",
    "                    continue\n",
    "\n",
    "                timestamp = dateutil.parser.parse(row['timestamp'], ignoretz=True)\n",
    "                lat = float(row['latitude'])\n",
    "                lon = float(row['longitude']) \n",
    "                alt = float(row['altitude'])\n",
    "                azimuth = np.radians(90 - float(row['az_velocity']))\n",
    "                elevation = np.radians(float(row['alt_velocity']))\n",
    "                speed = float(row['speed'])\n",
    "\n",
    "                metadata = {\n",
    "                    'classification': row['AlviraTracksTrack_Classification'],\n",
    "                    'sensor': 'Alvira',\n",
    "                    'reflection': float(row['AlviraTracksTrack_Reflection']),\n",
    "                    'score': float(row['AlviraTracksTrack_Score']),\n",
    "                }\n",
    "\n",
    "                if not self.min_reflection < metadata['reflection'] < self.max_reflection:\n",
    "                    continue\n",
    "\n",
    "                easting, northing, *_ = geodetic2enu(lat, lon, alt, self.lat, self.lon, self.alt)\n",
    "                rho, phi, _ = cart2sphere(easting, northing, alt)\n",
    "                dx, dy, dz = sphere2cart(speed, azimuth, elevation)\n",
    "\n",
    "                yield timestamp, {Detection(\n",
    "                    [Bearing(phi), rho, dx, dy], timestamp=timestamp,\n",
    "                    metadata=metadata, measurement_model=self.model)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alvira_file = '../../../data/ALVIRA_rdp.csv'\n",
    "rdp_reader = RDPReader( # Elevation, bearing, range\n",
    "    alvira_file,\n",
    "    pos_noise_diag=[(np.pi/4)**2, np.radians(1)**2, 25**2], \n",
    "    vel_noise_diag=[1, 1, 1],\n",
    "    min_reflection=-np.inf, max_reflection=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alvira_file = '../../../data/ALVIRA_rdp.csv'\n",
    "alvira = ALVIRAReader_mod( # Bearing, range\n",
    "    alvira_file,\n",
    "    pos_noise_diag=[np.radians(1)**2, 25**2], vel_noise_diag=[1, 1],\n",
    "    min_reflection=-np.inf, max_reflection=35,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reform Alvira file to look like RDP\n",
    "Adding in rho, theta, x, and y to make the Alvira file look like our RDP file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pymap3d import geodetic2enu\n",
    "import pyproj\n",
    "# geodesic = pyproj.Geod(ellps='WGS84')\n",
    "from pymap3d import geodetic2enu\n",
    "\n",
    "from stonesoup.functions import cart2sphere\n",
    "from stonesoup.functions import pol2cart \n",
    "from math import pi\n",
    "\n",
    "METERS_in_NM = 1852\n",
    "lat, lon, alt = 51.52126391, 5.85862734, 31\n",
    "\n",
    "alvira_df = pd.read_csv(alvira_file)\n",
    "alvira_df['alt'] = alt\n",
    "\n",
    "# Using code from Kaggle\n",
    "alvira_df['translation_offset'] = alvira_df.apply(lambda x:\n",
    "                                                  geodetic2enu(x.latitude, x.longitude, x.altitude, lat, lon, alt ),\n",
    "                                                  axis=1)\n",
    "\n",
    "alvira_df['easting'], alvira_df['northing'], alvira_df['upping'] = zip(*alvira_df['translation_offset'])\n",
    "\n",
    "alvira_df['rho'], alvira_df['phi'], _ = zip(*alvira_df.apply(lambda x:\n",
    "                                                            cart2sphere(x.easting, x.northing, x.altitude), \n",
    "                                                            axis=1)\n",
    "                                            )\n",
    "\n",
    "\n",
    "# alvira_df['theta'], alvira_df['back_theta'], alvira_df['distance'] = zip(*alvira_df.apply(lambda x:\n",
    "#                                                                                 geodesic.inv( lon, lat, x.longitude, x.latitude),\n",
    "#                                                                                 axis=1)\n",
    "#                                                                     )\n",
    "\n",
    "# alvira_df.loc[alvira_df.theta<0, 'theta'] = 2*pi + alvira_df.loc[alvira_df.theta<0, 'theta']\n",
    "# alvira_df['theta_rad'] = np.deg2rad(alvira_df.theta)\n",
    "\n",
    "# # alvira_df['rho'] = alvira_df['distance']/METERS_in_NM\n",
    "# alvira_df['rho'] = alvira_df['distance']\n",
    "# alvira_df.loc[alvira_df.theta<0, 'theta'] = 360 + alvira_df.loc[alvira_df.theta<0, 'theta']\n",
    "\n",
    "# alvira_df['x'], alvira_df['y'] = zip(*alvira_df.apply(lambda p: pol2cart(p.rho, p.phi), axis=1))\n",
    "\n",
    "alvira_df.to_csv(alvira_file, index=False)\n",
    "alvira_df.loc[~alvira_df.latitude.isna(), ['latitude','longitude','easting','northing','upping','rho','phi']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Stone Soup to my Coordinate Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sin, cos\n",
    "def polar_to_cartesian(rho, theta):\n",
    "    \"\"\"Convert polar coordinates to cartesian;\n",
    "    Y = North, clockwise theta\n",
    "\n",
    "    Given:\n",
    "    rho: radius in NM\n",
    "    theta: in degrees\n",
    "    \n",
    "    Return:\n",
    "    x: NM\n",
    "    y: NM\n",
    "    \"\"\"\n",
    "    \n",
    "    theta_rad = theta * pi/180\n",
    "    x = rho * sin(theta_rad)\n",
    "    y = rho * cos(theta_rad)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyproj\n",
    "geodesic = pyproj.Geod(ellps='WGS84')\n",
    "\n",
    "alvira_df['theta'], alvira_df['back_theta'], alvira_df['distance'] = zip(*alvira_df.apply(\n",
    "        lambda x: geodesic.inv( lon, lat, x.longitude, x.latitude),axis=1))\n",
    "\n",
    "alvira_df.loc[alvira_df.theta<0, 'theta'] = 360 + alvira_df.loc[alvira_df.theta<0, 'theta']\n",
    "\n",
    "alvira_df['x1'], alvira_df['y1'] = zip(*alvira_df.apply(lambda p: polar_to_cartesian(p.distance, p.theta), axis=1))\n",
    "\n",
    "alvira_df['phi_deg'] = np.rad2deg(alvira_df.phi)\n",
    "\n",
    "alvira_df.loc[~alvira_df.latitude.isna(), ['latitude','longitude','rho','phi','phi_deg','distance','theta','x1','y1']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alvira_df.plot.scatter(x='latitude',y='longitude')\n",
    "alvira_df.plot.scatter(x='x1',y='y1')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alvira_df.plot.scatter(x='longitude',y='latitude')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stonesoup.plotter import Plotter\n",
    "plotter = Plotter()\n",
    "\n",
    "plotter.plot_measurements(\n",
    "        [detection[1] for detection in alvira.detections_gen()], [0, 2])\n",
    "        \n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdp = RDPReader(rdp_file,\n",
    "                pos_noise_diag=[np.radians(1)**2, 25**2], \n",
    "                vel_noise_diag=[1, 1],\n",
    "                min_reflection=-np.inf, \n",
    "                max_reflection=np.inf\n",
    ")\n",
    "\n",
    "rdp_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdp_data['x_m'] = rdp_data.x * METERS_in_NM\n",
    "rdp_data['y_m'] = rdp_data.y * METERS_in_NM\n",
    "\n",
    "rdp_data.plot.scatter(x='x_m',y = 'y_m', color='red', marker=\"+\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = Plotter()\n",
    "\n",
    "plotter.plot_measurements(\n",
    "        [detection[1] for detection in rdp.detections_gen()], \n",
    "        mapping=[0, 2],\n",
    "        measurements_label='RDP', \n",
    "        color=\"red\",\n",
    "        alpha=0.3,\n",
    "        marker=\"+\",\n",
    "        zorder=10)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_timestamps(start_time, end_time):\n",
    "    total_seconds = (end_time - start_time).total_seconds()\n",
    "    return [start_time + timedelta(seconds=n) for n in range(ceil(total_seconds))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adsb = ADSBTruthReader(adsb_file)\n",
    "ground_truth = set()\n",
    "for time, truths in adsb:\n",
    "    ground_truth.update(truths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = Plotter()\n",
    "plotter.plot_ground_truths(ground_truth, [0, 2], color='blue', marker='s', markerfacecolor='none', alpha=0.3)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground_truth=True\n",
    "\n",
    "timestamps = generate_timestamps(rdp_data['timestamp'].min(), rdp_data['timestamp'].max())\n",
    "\n",
    "plotter = AnimatedPlotterly(timestamps, tail_length=0.3, sim_duration=1, equal_size=True)\n",
    "plotter.fig.update_layout(width=800, height=800)\n",
    "rdp_measurements = []\n",
    "\n",
    "for detection in [detection[1] for detection in rdp.detections_gen()]:\n",
    "    rdp_measurements.append(detection)\n",
    "\n",
    "plotter.plot_measurements(rdp_measurements,\n",
    "                          mapping=[0, 2],\n",
    "                          measurements_label='RDP',\n",
    "                          marker=dict(color='rgba(255, 0, 0, 0.7)',\n",
    "                                      size=5, \n",
    "                                      symbol=\"cross\")                \n",
    ")\n",
    "\n",
    "plotter.plot_ground_truths(ground_truth, \n",
    "                           mapping=[0, 2], \n",
    "                           mode='markers', \n",
    "                           marker=dict(color='rgba(0, 0, 255, 0.2)',\n",
    "                                      size=5, \n",
    "                                      symbol=\"square-open\")\n",
    "                            )\n",
    "\n",
    "plotter.fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Predictor and Updater\n",
    "\n",
    "Create our model used for prediction, using 3 CV models, making state space $ x, \\dot x, y, \\dot y, z, \\dot z $; where $x$ is east, $y$ is north, and $z$ is altitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_model = CombinedLinearGaussianTransitionModel([ConstantVelocity(40)]*3)\n",
    "predictor = ExtendedKalmanPredictor(transition_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create our updater. We won't define a model here, as we'll used the ones assigned to detections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updater = ExtendedKalmanUpdater(measurement_model=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Hypothesiser and Data Associator\n",
    "\n",
    "This create hypothesier and data associator componets used for associating tracks and detections. Also create slightly stricter versions of these to limit track initiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "from stonesoup.hypothesiser.distance import DistanceHypothesiser\n",
    "from stonesoup.models.measurement.nonlinear import CombinedReversibleGaussianMeasurementModel\n",
    "from stonesoup.gater.base import Gater\n",
    "from stonesoup.base import Property\n",
    "\n",
    "class SensorLocationGater(Gater):\n",
    "\n",
    "    hypothesiser: DistanceHypothesiser = Property(\n",
    "        doc='hypothesiser to use when far enough away from sensors')\n",
    "    pos_mapping: Tuple[int, int] = Property(default=(0, 2))\n",
    "    min_distance_from_sensor: float = Property(default=80)\n",
    "\n",
    "    def hypothesise(self, track, detections, timestamp, *args, **kwargs):\n",
    "        for detection in detections:\n",
    "            measurement_model = detection.measurement_model\n",
    "            if isinstance(measurement_model, CombinedReversibleGaussianMeasurementModel):\n",
    "                measurement_model = measurement_model.model_list[0]\n",
    "            sensor_location = measurement_model.translation_offset[:, 0][:len(self.pos_mapping)]\n",
    "\n",
    "            track_location = track.state_vector[self.pos_mapping, 0]\n",
    "            difference = track_location - sensor_location\n",
    "            euclidean_dist = np.sqrt(difference[0] ** 2 + difference[1] ** 2)\n",
    "\n",
    "            if euclidean_dist <= self.min_distance_from_sensor:\n",
    "                return self.hypothesiser.hypothesise(track, set(), timestamp)\n",
    "        return self.hypothesiser.hypothesise(track, detections, timestamp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesiser = DistanceHypothesiser(predictor, updater, measure=Mahalanobis(), missed_distance=4)\n",
    "\n",
    "# This is reducing missed distance to 2 units of Mahalanobis i.e. std. deviation, for initialisation\n",
    "init_hypothesiser = DistanceHypothesiser(predictor, updater, measure=Mahalanobis(), missed_distance=2)\n",
    "\n",
    "# This will ignore sensor data when drone within min. distance. Avoids bad bearing/elevation measurements\n",
    "# causing issues in particular with rapid changes in velocity.\n",
    "hypothesiser = SensorLocationGater(hypothesiser, min_distance_from_sensor=80)\n",
    "init_hypothesiser = SensorLocationGater(init_hypothesiser, min_distance_from_sensor=80)\n",
    "\n",
    "data_associator = GNNWith2DAssignment(hypothesiser)\n",
    "init_data_associator = GNNWith2DAssignment(init_hypothesiser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Track Initiators and Deleters\n",
    "\n",
    "The deleters in this example will remove tracks where no detections have been associated for a period of time,\n",
    "or uncertainty in position has grown too large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deleter = CompositeDeleter(\n",
    "    [\n",
    "        UpdateTimeDeleter(time_since_update=timedelta(seconds=30), delete_last_pred=True),\n",
    "        CovarianceBasedDeleter(covar_trace_thresh=5000, mapping=[0, 2], delete_last_pred=True),\n",
    "    ],\n",
    "    intersect=False)\n",
    "\n",
    "# More aggressive deletion when trying to initalise a track\n",
    "init_deleter = CompositeDeleter(\n",
    "    [\n",
    "        UpdateTimeDeleter(time_since_update=timedelta(seconds=15), delete_last_pred=True),\n",
    "        CovarianceBasedDeleter(covar_trace_thresh=3000, mapping=[0, 2], delete_last_pred=True),\n",
    "    ],\n",
    "    intersect=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our initiator will use the detections position/velocity from the radar for easting/northing $x$/$y$ (hence just leaving prior state vector and covariance `0` for those elements), but use a prior value for altitude where 2D Radar initialises the track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = GaussianState([0, 0, 4000, 0, 0, 0], np.diag([0, 0, 0, 0, 1000, 100]))\n",
    "\n",
    "base_initiator = MultiMeasurementInitiator(\n",
    "    prior_state=prior,\n",
    "    measurement_model=None,\n",
    "    deleter=init_deleter,\n",
    "    data_associator=init_data_associator,\n",
    "    updater=updater,\n",
    "    min_points=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stonesoup.base import Property\n",
    "from stonesoup.initiator import Initiator\n",
    "\n",
    "class rdp_initiator(Initiator):\n",
    "\n",
    "    initiator: Initiator = Property()\n",
    "\n",
    "    def initiate(self, detections, timestamp, **kwargs):\n",
    "        for detection in detections:\n",
    "            # if detection.metadata['sensor'] == 'RDP':\n",
    "            return self.initiator.initiate(detections, timestamp, **kwargs)\n",
    "        return self.initiator.initiate(set(), timestamp, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Tracker and Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = MultiDataFeeder([rdp])\n",
    "initiator = rdp_initiator(base_initiator)\n",
    "\n",
    "tracker = MultiTargetTracker(\n",
    "    detector=detector,\n",
    "    initiator=initiator,\n",
    "    deleter=deleter,\n",
    "    data_associator=data_associator,\n",
    "    updater=updater,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = set()\n",
    "detections = set()\n",
    "try:\n",
    "    for time, ctracks in tracker:\n",
    "        tracks |= ctracks\n",
    "        detections |= tracker.detector.detections\n",
    "except:\n",
    "    pass\n",
    "len(tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stonesoup.plotter import Plotter\n",
    "\n",
    "plotter = Plotter()\n",
    "# sensor='Alvira'\n",
    "plotter.plot_measurements(\n",
    "        {detection for detection in detections}, \n",
    "        mapping=[0, 2],\n",
    "        measurements_label='RDP', \n",
    "        color='red', \n",
    "        marker='+',\n",
    "        alpha=0.3,\n",
    "        zorder=10)\n",
    "plotter.plot_ground_truths(ground_truth, [0, 2], color='black')\n",
    "plotter.plot_tracks(tracks, [0,2], uncertainty=True)\n",
    "for name, position in sensor_positions.items():\n",
    "    plotter.ax.scatter(*position, label=name, marker='X')\n",
    "    plotter.ax.text(*position+20, name.title())\n",
    "track_xlim = plotter.ax.get_xlim()\n",
    "track_ylim = plotter.ax.get_ylim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asterix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
